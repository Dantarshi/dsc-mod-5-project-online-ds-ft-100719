{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Ice Asortse\n",
    "* Student pace: full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: James Irving (phd)\n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Retention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Employee retention has been a very big issue in organizations for a long time. A lot of businesses and organizations have struggled in keeping their employees happy and satisfied. We will attempt to use data available to us to create a model that can predict employee attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing neccessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the neccesarry libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (accuracy_score, log_loss, classification_report)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # import 'train_test_split'\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Common sklearn Model Helpers\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "3  ...                         3            80                 0   \n",
       "4  ...                         4            80                 1   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "3                  8                      3               3               8   \n",
       "4                  6                      3               3               2   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "3                  7                        3                     0  \n",
       "4                  2                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data from excelinto the notebook\n",
    "df = pd.read_csv(r'C:\\Users\\Ice Asortse\\FlatironData\\projectmod5\\dsc-mod-5-project-online-ds-ft-100719\\WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data and pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         False\n",
       "Attrition                   False\n",
       "BusinessTravel              False\n",
       "DailyRate                   False\n",
       "Department                  False\n",
       "DistanceFromHome            False\n",
       "Education                   False\n",
       "EducationField              False\n",
       "EmployeeCount               False\n",
       "EmployeeNumber              False\n",
       "EnvironmentSatisfaction     False\n",
       "Gender                      False\n",
       "HourlyRate                  False\n",
       "JobInvolvement              False\n",
       "JobLevel                    False\n",
       "JobRole                     False\n",
       "JobSatisfaction             False\n",
       "MaritalStatus               False\n",
       "MonthlyIncome               False\n",
       "MonthlyRate                 False\n",
       "NumCompaniesWorked          False\n",
       "Over18                      False\n",
       "OverTime                    False\n",
       "PercentSalaryHike           False\n",
       "PerformanceRating           False\n",
       "RelationshipSatisfaction    False\n",
       "StandardHours               False\n",
       "StockOptionLevel            False\n",
       "TotalWorkingYears           False\n",
       "TrainingTimesLastYear       False\n",
       "WorkLifeBalance             False\n",
       "YearsAtCompany              False\n",
       "YearsInCurrentRole          False\n",
       "YearsSinceLastPromotion     False\n",
       "YearsWithCurrManager        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null or missing data\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 35 columns):\n",
      "Age                         1470 non-null int64\n",
      "Attrition                   1470 non-null object\n",
      "BusinessTravel              1470 non-null object\n",
      "DailyRate                   1470 non-null int64\n",
      "Department                  1470 non-null object\n",
      "DistanceFromHome            1470 non-null int64\n",
      "Education                   1470 non-null int64\n",
      "EducationField              1470 non-null object\n",
      "EmployeeCount               1470 non-null int64\n",
      "EmployeeNumber              1470 non-null int64\n",
      "EnvironmentSatisfaction     1470 non-null int64\n",
      "Gender                      1470 non-null object\n",
      "HourlyRate                  1470 non-null int64\n",
      "JobInvolvement              1470 non-null int64\n",
      "JobLevel                    1470 non-null int64\n",
      "JobRole                     1470 non-null object\n",
      "JobSatisfaction             1470 non-null int64\n",
      "MaritalStatus               1470 non-null object\n",
      "MonthlyIncome               1470 non-null int64\n",
      "MonthlyRate                 1470 non-null int64\n",
      "NumCompaniesWorked          1470 non-null int64\n",
      "Over18                      1470 non-null object\n",
      "OverTime                    1470 non-null object\n",
      "PercentSalaryHike           1470 non-null int64\n",
      "PerformanceRating           1470 non-null int64\n",
      "RelationshipSatisfaction    1470 non-null int64\n",
      "StandardHours               1470 non-null int64\n",
      "StockOptionLevel            1470 non-null int64\n",
      "TotalWorkingYears           1470 non-null int64\n",
      "TrainingTimesLastYear       1470 non-null int64\n",
      "WorkLifeBalance             1470 non-null int64\n",
      "YearsAtCompany              1470 non-null int64\n",
      "YearsInCurrentRole          1470 non-null int64\n",
      "YearsSinceLastPromotion     1470 non-null int64\n",
      "YearsWithCurrManager        1470 non-null int64\n",
      "dtypes: int64(26), object(9)\n",
      "memory usage: 402.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking data types and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data contains both categorical and numerical data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe is (1470, 35)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataframe is {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>36.923810</td>\n",
       "      <td>802.485714</td>\n",
       "      <td>9.192517</td>\n",
       "      <td>2.912925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1024.865306</td>\n",
       "      <td>2.721769</td>\n",
       "      <td>65.891156</td>\n",
       "      <td>2.729932</td>\n",
       "      <td>2.063946</td>\n",
       "      <td>...</td>\n",
       "      <td>2.712245</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.793878</td>\n",
       "      <td>11.279592</td>\n",
       "      <td>2.799320</td>\n",
       "      <td>2.761224</td>\n",
       "      <td>7.008163</td>\n",
       "      <td>4.229252</td>\n",
       "      <td>2.187755</td>\n",
       "      <td>4.123129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9.135373</td>\n",
       "      <td>403.509100</td>\n",
       "      <td>8.106864</td>\n",
       "      <td>1.024165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>602.024335</td>\n",
       "      <td>1.093082</td>\n",
       "      <td>20.329428</td>\n",
       "      <td>0.711561</td>\n",
       "      <td>1.106940</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>7.780782</td>\n",
       "      <td>1.289271</td>\n",
       "      <td>0.706476</td>\n",
       "      <td>6.126525</td>\n",
       "      <td>3.623137</td>\n",
       "      <td>3.222430</td>\n",
       "      <td>3.568136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>491.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1020.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1157.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1555.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>83.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1499.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2068.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age    DailyRate  DistanceFromHome    Education  EmployeeCount  \\\n",
       "count  1470.000000  1470.000000       1470.000000  1470.000000         1470.0   \n",
       "mean     36.923810   802.485714          9.192517     2.912925            1.0   \n",
       "std       9.135373   403.509100          8.106864     1.024165            0.0   \n",
       "min      18.000000   102.000000          1.000000     1.000000            1.0   \n",
       "25%      30.000000   465.000000          2.000000     2.000000            1.0   \n",
       "50%      36.000000   802.000000          7.000000     3.000000            1.0   \n",
       "75%      43.000000  1157.000000         14.000000     4.000000            1.0   \n",
       "max      60.000000  1499.000000         29.000000     5.000000            1.0   \n",
       "\n",
       "       EmployeeNumber  EnvironmentSatisfaction   HourlyRate  JobInvolvement  \\\n",
       "count     1470.000000              1470.000000  1470.000000     1470.000000   \n",
       "mean      1024.865306                 2.721769    65.891156        2.729932   \n",
       "std        602.024335                 1.093082    20.329428        0.711561   \n",
       "min          1.000000                 1.000000    30.000000        1.000000   \n",
       "25%        491.250000                 2.000000    48.000000        2.000000   \n",
       "50%       1020.500000                 3.000000    66.000000        3.000000   \n",
       "75%       1555.750000                 4.000000    83.750000        3.000000   \n",
       "max       2068.000000                 4.000000   100.000000        4.000000   \n",
       "\n",
       "          JobLevel  ...  RelationshipSatisfaction  StandardHours  \\\n",
       "count  1470.000000  ...               1470.000000         1470.0   \n",
       "mean      2.063946  ...                  2.712245           80.0   \n",
       "std       1.106940  ...                  1.081209            0.0   \n",
       "min       1.000000  ...                  1.000000           80.0   \n",
       "25%       1.000000  ...                  2.000000           80.0   \n",
       "50%       2.000000  ...                  3.000000           80.0   \n",
       "75%       3.000000  ...                  4.000000           80.0   \n",
       "max       5.000000  ...                  4.000000           80.0   \n",
       "\n",
       "       StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "count       1470.000000        1470.000000            1470.000000   \n",
       "mean           0.793878          11.279592               2.799320   \n",
       "std            0.852077           7.780782               1.289271   \n",
       "min            0.000000           0.000000               0.000000   \n",
       "25%            0.000000           6.000000               2.000000   \n",
       "50%            1.000000          10.000000               3.000000   \n",
       "75%            1.000000          15.000000               3.000000   \n",
       "max            3.000000          40.000000               6.000000   \n",
       "\n",
       "       WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  \\\n",
       "count      1470.000000     1470.000000         1470.000000   \n",
       "mean          2.761224        7.008163            4.229252   \n",
       "std           0.706476        6.126525            3.623137   \n",
       "min           1.000000        0.000000            0.000000   \n",
       "25%           2.000000        3.000000            2.000000   \n",
       "50%           3.000000        5.000000            3.000000   \n",
       "75%           3.000000        9.000000            7.000000   \n",
       "max           4.000000       40.000000           18.000000   \n",
       "\n",
       "       YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "count              1470.000000           1470.000000  \n",
       "mean                  2.187755              4.123129  \n",
       "std                   3.222430              3.568136  \n",
       "min                   0.000000              0.000000  \n",
       "25%                   0.000000              2.000000  \n",
       "50%                   1.000000              3.000000  \n",
       "75%                   3.000000              7.000000  \n",
       "max                  15.000000             17.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age distribution shows most of the employees are between 25 to 45 years old.\n",
    "EmployeeCount and StandardHours are constant values for all employees.\n",
    "EmployeeNumber is unique id for each employee.\n",
    "Over18 is constant meaning working age starts from 18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EducationField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EducationField'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OverTime = pd.DataFrame(columns=[\"OverTime\", \"% of Leavers\"])\n",
    "i=0\n",
    "for field in list(df['OverTime'].unique()):\n",
    "    ratio = df[(df['OverTime']==field)&(df['Attrition']==\"Yes\")].shape[0] / df[df['OverTime']==field].shape[0]\n",
    "    df_OverTime.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attrition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of Current Employees is {:.1f}% and of Ex-employees is: {:.1f}%\".format(\n",
    "    df[df['Attrition'] == 'No'].shape[0] / df.shape[0]*100,\n",
    "    df[df['Attrition'] == 'Yes'].shape[0] / df.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use chart\n",
    "df['Attrition'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.copy()\n",
    "df_corr['Target'] = df_corr['Attrition'].apply(lambda x:0 if x == 'No' else 1)\n",
    "df_corr = df_corr.drop(['Attrition', 'EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18'], axis=1)\n",
    "correlations = df_corr.corr()['Target'].sort_values()\n",
    "\n",
    "print('Most Positive Correlations: \\n', correlations.tail(5))\n",
    "print('\\nMost Negative Correlations: \\n', correlations.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "corr = df_corr.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# Heatmap\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr,vmax=.5,mask=mask, annot=True, fmt='.2f', linewidths=.2, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA summary\n",
    "1. There are no missing data \n",
    "2. Dataset has correct data types\n",
    "3. Positive correlation with target are:\n",
    "   Performance Rating, Monthly Rate, Num    Companies Worked, Distance From Home.\n",
    "4. Negative correlations with target are:\n",
    "   Total Working Years, Job Level, Years In Current Role, and Monthly Income.\n",
    "5. Some features are redundant for our analysis such as: EmployeeCount, EmployeeNumber, StandardHours, and Over18.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping some column that are redundant\n",
    "df = df.drop(['EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting out categorical variables\n",
    "cat_var = df.select_dtypes('object').columns\n",
    "cat_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(df['Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = le.fit_transform(df['Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.inverse_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoders= {}\n",
    "for col in cat_var:\n",
    "    le = LabelEncoder()\n",
    "    temp = le.fit_transform(df[col])\n",
    "    df[col] = temp\n",
    "    Encoders[col] = le\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoders['Attrition'].inverse_transform(df['Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of Full Encoded Dataset: {}'. format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling using minmaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 3))\n",
    "df_col = list(df.columns)\n",
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 3))\n",
    "df_col = list(df.columns)\n",
    "df_col.remove('Attrition')\n",
    "for col in df_col:\n",
    "    df[col] = df[col].astype(float)\n",
    "    df[[col]] = scaler.fit_transform(df[[col]])\n",
    "df['Attrition'] = pd.to_numeric(df['Attrition'], downcast='float')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Attrition'].copy()\n",
    "type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Attrition'], axis=1, inplace=True)\n",
    "print('Size of Full dataset is: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a heavy imbalance of class( we have more employesss with 0 than 1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.25, random_state=24) #stratify=target) \n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "\n",
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SMOTE to handle imbalance target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train)\n",
    "X_train = pd.DataFrame(X_train, columns=df.columns)\n",
    "y_train = pd.Series(y_train, name=y_test.name)\n",
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider Random Forest, Support Vector Machine(SVM) and Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common sklearn Model Helpers\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of algorithms to consider and set performance measure\n",
    "models = []\n",
    "models.append(('Random Forest', RandomForestClassifier(n_estimators=100, random_state=24)))\n",
    "models.append(('Decision Tree Classifier', DecisionTreeClassifier(random_state=24)))\n",
    "models.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state=24,\n",
    "                                                         class_weight='balanced')))\n",
    "models.append(('Gaussian NB', GaussianNB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "# set table to table to populate with performance results\n",
    "col = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', \n",
    "       'Accuracy Mean', 'Accuracy STD']\n",
    "df_results = pd.DataFrame(columns=col)\n",
    "i = 1\n",
    "# evaluate each model using cross-validation\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=15, random_state=24)  # 15-fold cross-validation\n",
    "\n",
    "    cv_acc_results = model_selection.cross_val_score(  # accuracy scoring\n",
    "    model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    cv_auc_results = model_selection.cross_val_score(  # roc_auc scoring\n",
    "            model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "    \n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    df_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "df_results.sort_values(by=['ROC AUC Mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "fig.suptitle('Algorithm ROC AUC Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(auc_results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "fig.suptitle('Algorithm Accuracy Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(acc_results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(class_weight = \"balanced\",\n",
    "                                       random_state=24)\n",
    "param_grid = {'n_estimators': [50, 75, 100, 125, 150, 175],\n",
    "              'min_samples_split':[2,4,6,8,10],\n",
    "              'min_samples_leaf': [1, 2, 3, 4],\n",
    "              'max_depth': [5, 10, 15, 20, 25]}\n",
    "\n",
    "grid_obj = GridSearchCV(rf_classifier,\n",
    "                        iid=True,\n",
    "                        return_train_score=True,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='roc_auc',\n",
    "                        cv=10)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "rf_opt = grid_fit.best_estimator_\n",
    "\n",
    "print('='*20)\n",
    "print(\"best params: \" + str(grid_obj.best_estimator_))\n",
    "print(\"best params: \" + str(grid_obj.best_params_))\n",
    "print('best score:', grid_obj.best_score_)\n",
    "print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = rf_opt.feature_importances_\n",
    "indices = np.argsort(importances)[::-1] # Sort feature importances in descending order\n",
    "names = [X_train.columns[i] for i in indices] # Rearrange feature names so they match the sorted feature importances\n",
    "plt.figure(figsize=(15, 7)) # Create plot\n",
    "plt.title(\"Feature Importance\") # Create plot title\n",
    "plt.bar(range(X_train.shape[1]), importances[indices]) # Add bars\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation=45, ha='right', size= 12) # Add feature names as x-axis labels\n",
    "plt.show() # Show plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_opt.feature_importances_\n",
    "df_param_coeff = pd.DataFrame(columns=['Feature', 'Coefficient'])\n",
    "for i in range(30):\n",
    "    feat = X_train.columns[i]\n",
    "    coeff = importances[i]\n",
    "    df_param_coeff.loc[i] = (feat, coeff)\n",
    "df_param_coeff.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "df_param_coeff = df_param_coeff.reset_index(drop=True)\n",
    "df_param_coeff.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, rf_opt.predict(X_test))\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=0.5)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of RandomForest Regression Classifier on test set: {:.2f}'.format(rf_opt.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for the optimised RF Regression\n",
    "rf_opt.fit(X_train, y_train)\n",
    "print(classification_report(y_test, rf_opt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, recall_score, log_loss\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.fit(X_train, y_train) # fit optimised model to the training data\n",
    "probs = rf_opt.predict_proba(X_test) # predict probabilities\n",
    "probs = probs[:, 1] # we will only keep probabilities associated with the employee leaving\n",
    "rf_opt_roc_auc = roc_auc_score(y_test, probs) # calculate AUC score using test dataset\n",
    "print('AUC score: %.3f' % rf_opt_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.StratifiedKFold(n_splits=15, random_state=24)\n",
    "modelCV = LogisticRegression(solver='liblinear',\n",
    "                             class_weight=\"balanced\", \n",
    "                             random_state=24)\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(\n",
    "    modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"AUC score (STD): %.2f (%.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.arange(1e-03, 2, 0.01)} # hyper-parameter list to fine-tune\n",
    "log_gs = GridSearchCV(LogisticRegression(solver='liblinear', # setting GridSearchCV\n",
    "                                         class_weight=\"balanced\", \n",
    "                                         random_state=7),\n",
    "                      iid=True,\n",
    "                      return_train_score=True,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='roc_auc',\n",
    "                      cv=10)\n",
    "\n",
    "log_grid = log_gs.fit(X_train, y_train)\n",
    "log_opt = log_grid.best_estimator_\n",
    "results = log_gs.cv_results_\n",
    "\n",
    "print('='*20)\n",
    "print(\"best params: \" + str(log_gs.best_estimator_))\n",
    "print(\"best params: \" + str(log_gs.best_params_))\n",
    "print('best score:', log_gs.best_score_)\n",
    "print('='*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, log_opt.predict(X_test))\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression Classifier on test set: {:.2f}'.format(log_opt.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for the optimised Log Regression\n",
    "log_opt.fit(X_train, y_train)\n",
    "print(classification_report(y_test, log_opt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class O = employee that are not leaving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class 1 = employee that leaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_opt.fit(X_train, y_train) # fit optimised model to the training data\n",
    "probs = log_opt.predict_proba(X_test) # predict probabilities\n",
    "probs = probs[:, 1] # we will only keep probabilities associated with the employee leaving\n",
    "logit_roc_auc = roc_auc_score(y_test, probs) # calculate AUC score using test dataset\n",
    "print('AUC score: %.3f' % logit_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ROC Graph\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, log_opt.predict_proba(X_test)[:,1])\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, rf_opt.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Logistic Regression ROC\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "#Plot Random Forest ROC\n",
    "plt.plot(rf_fpr, rf_tpr, label='Random Forest (area = %0.2f)' % rf_opt_roc_auc)\n",
    "#Plot Base Rate ROC\n",
    "plt.plot([0,1], [0,1],label='Base Rate' 'k--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Graph')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tunning Logistic Regression and Random Forest Classifier, Logistic regression has a better AUC by just 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retraining of the model is very important as new data emerges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In putting up a strategic plan to improve retention of employees, certain feature are of more importance than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the people leaving have cartain indicators in common:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overtime: Most people that work over time are more likely to leave the company so the should make provision for providing enough manpower to handle a task to avoid excess overtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JobLevel: Employees with higher job levels are less likely to leave the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StockOptionLevel: Employees with more StockOptionLevel are less likely to leave. it is critical for the company to consider competitive wages in form employee stock options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JobSatisfaction: Employees who have higher level of job satisfaction are more likely to stay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MonthlyIncome: Employees with higher monthly income are less likely to leave the company so the company, Hence the company can consider industry benchmark to offer competitive wages in order to retain employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
